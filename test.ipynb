{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torch.distributions import Beta\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torchvision\n",
    "from resnest.torch import resnest50\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.dataset import SpectrogramDataset\n",
    "import src.configuration as C\n",
    "from src.metric import LWLRAP\n",
    "from src.conformer import ConformerBlock\n",
    "import pytorch_lightning as pl\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from pytorch_lightning.metrics import F1\n",
    "\n",
    "class ConformerSED(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.att_block = AttBlockV2(128, 24, activation=\"sigmoid\")\n",
    "\n",
    "        self.interpolate_ratio = 30  # Downsampled ratio\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3,3)), nn.ReLU(), nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3,3)), nn.ReLU(), nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3)), nn.ReLU(), nn.MaxPool2d((1,2)),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3)), nn.ReLU(), nn.MaxPool2d((1,2)),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3,3)), nn.ReLU(), nn.MaxPool2d((1,2)),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3,3)), nn.ReLU(), nn.MaxPool2d((1,2)),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3,3)), nn.ReLU(), nn.MaxPool2d((1,2))\n",
    "        )\n",
    "        self.conformerblock = ConformerBlock(dim=128)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        frames_num = input.size(3)\n",
    "\n",
    "        # (batch_size, channels, freq, frames) ex->(120, 1408, 7, 12)\n",
    "        x = self.convblock(input)\n",
    "        x = self.conformerblock(x)\n",
    "    \n",
    "        # (batch_size, channels, frames) ex->(120, 1408, 12)\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        # channel smoothing\n",
    "        # channel次元上でpoolingを行う\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)  # torch.Size([120, 1408, 12]) -> torch.Size([120, 12, 1408])\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)  # torch.Size([120, 12, 1408]) -> torch.Size([120, 1408, 12])\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)  # claにsigmoidをかけない状態でclipwiseを計算\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)  # torch.Size([120, 12, 24])\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)  # torch.Size([120, 12, 24])\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output, self.interpolate_ratio)  # n_time次元上でをupsampling\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)  # n_timesの最後の値で穴埋めしてframes_numに合わせる\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, self.interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"clipwise_output\": clipwise_output,\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"segmentwise_logit\": segmentwise_logit  \n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "# n_timeの最後の値で穴埋めしてframe数になるようにする\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. \n",
    "       The pad value is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "            bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "            bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "\n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):  \n",
    "        \"\"\"\n",
    "        Args:\n",
    "        x: (n_samples, n_in, n_time)  ex)torch.Size([120, 1408, 12])\n",
    "        Outputs:\n",
    "        x:(batch_size, classes_num) ex)torch.Size([120, 24])\n",
    "        norm_att: batch_size, classes_num, n_time) ex)torch.Size([120, 24, 12])\n",
    "        cla: batch_size, classes_num, n_time) ex)torch.Size([120, 24, 12])\n",
    "        \"\"\"\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)  # torch.Size([120, 24, 12]) クラス数に圧縮/valueを-1~1/n_timeの次元の総和=１に変換\n",
    "        cla = self.nonlinear_transform(self.cla(x))  # self.cla()=self.att()/sigmoid変換\n",
    "        x = torch.sum(norm_att * cla, dim=2)  # 要素同士の積 torch.Size([120, 24]): (n_samples, n_class)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConformerSED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ConformerSED(\n",
       "  (att_block): AttBlockV2(\n",
       "    (att): Conv1d(128, 24, kernel_size=(1,), stride=(1,))\n",
       "    (cla): Conv1d(128, 24, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (convblock): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (16): ReLU()\n",
       "    (17): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conformerblock): ConformerBlock(\n",
       "    (ff1): Scale(\n",
       "      (fn): PreNorm(\n",
       "        (fn): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): Swish()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (attn): PreNorm(\n",
       "      (fn): Attention(\n",
       "        (to_q): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (to_kv): Linear(in_features=128, out_features=1024, bias=False)\n",
       "        (to_out): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (rel_pos_emb): Embedding(1025, 64)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (conv): ConformerConvModule(\n",
       "      (net): Sequential(\n",
       "        (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Rearrange('b n c -> b c n')\n",
       "        (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (3): GLU()\n",
       "        (4): DepthWiseConv1d(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), groups=256)\n",
       "        )\n",
       "        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Swish()\n",
       "        (7): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "        (8): Rearrange('b c n -> b n c')\n",
       "        (9): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (ff2): Scale(\n",
       "      (fn): PreNorm(\n",
       "        (fn): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): Swish()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}